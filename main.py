# -*- coding: utf-8 -*-
"""math quizz.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bhVCO-cqDmcUw2edJirV_Y4d7pJlZ9KV
"""

# !pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain

import os
import re
import json
import inspect
from typing import List, Dict, Any
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from templates import QUESTION_PROMPT, NUMERICAL_EXTRACTION_PROMPT, SCRIPT_PROMPT, ANSWER_VARIATION_PROMPT
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

class MathPhysicsRAG:
    # def __init__(self, openai_api_key: str, model_name: str = "gpt-4-0125-preview"):
    def __init__(self, openai_api_key: str, model_name: str = "gpt-4o-mini"):
        # Set the OpenAI API key and initialize the language model
        os.environ['OPENAI_API_KEY'] = openai_api_key 
        self.llm = ChatOpenAI(model_name=model_name, temperature=0.8)
        self.setup_chains()  # Set up the processing chains

    def setup_chains(self):
        """Initialize the various chains used for question generation and processing."""
        self.question_chain = self.create_question_chain()  # Chain for generating questions
        self.numerical_extraction_chain = self.create_numerical_extraction_chain()  # Chain for extracting numbers
        self.script_chain = self.create_script_chain()  # Chain for generating solving scripts
        self.answer_variation_chain = self.create_answer_variation_chain()  # Chain for generating answer variations

    def create_question_chain(self):
        """Create a chain for generating math or physics questions."""
        # Use the imported question prompt
        question_prompt = ChatPromptTemplate.from_template(QUESTION_PROMPT)
        return question_prompt | self.llm | StrOutputParser()  # Combine prompt with LLM and output parser

    def create_numerical_extraction_chain(self):
        """Create a chain for extracting numerical values from questions."""
        # Use the imported numerical extraction prompt
        numerical_extraction_prompt = ChatPromptTemplate.from_template(NUMERICAL_EXTRACTION_PROMPT)
        return (
            {"question": RunnablePassthrough()}  # Input for the chain
            | numerical_extraction_prompt  # Combine with prompt
            | self.llm  # Use the language model
            | StrOutputParser()  # Parse the output
        )

    def create_script_chain(self):
        """Create a chain for generating Python scripts to solve questions."""
        # Use the imported script prompt
        script_prompt = ChatPromptTemplate.from_template(SCRIPT_PROMPT)
        return (
            {"question": RunnablePassthrough()}  # Input for the chain
            | script_prompt  # Combine with prompt
            | self.llm  # Use the language model
            | StrOutputParser()  # Parse the output
        )

    def create_answer_variation_chain(self):
        """Create a chain for generating variations of correct answers."""
        # Use the imported answer variation prompt
        answer_variation_prompt = ChatPromptTemplate.from_template(ANSWER_VARIATION_PROMPT)
        return (
            {"question": RunnablePassthrough(), "correct_answer": RunnablePassthrough(), "num_variations": RunnablePassthrough()}  # Inputs for the chain
            | answer_variation_prompt  # Combine with prompt
            | self.llm  # Use the language model
            | StrOutputParser()  # Parse the output
        )

    def generate_question(self, subject: str, grade_level: str, topic: str, toughness_level: str ) -> str:
        """Generate a question based on grade level and topic."""
        return self.question_chain.invoke({"subject": subject, "grade_level": grade_level, "topic": topic, "toughness_level": toughness_level})  # Invoke the question chain

    def extract_numericals(self, question: str) -> Dict[str, float]:
        """Extract numerical values from a question."""
        json_output = self.numerical_extraction_chain.invoke(question).strip('```json\n')  # Invoke the extraction chain
        try:
            return json.loads(json_output)  # Parse the JSON output
        except json.JSONDecodeError:
            print("Error: Invalid JSON output")  # Handle JSON parsing errors
            return {}

    def generate_solving_script(self, question: str, numericals: Dict[str, float]) -> str:
        """Generate a Python script to solve the question."""
        prompt = question + json.dumps(numericals)  # Combine question and numericals for the prompt
        return self.script_chain.invoke(prompt)  # Invoke the script chain

    def execute_solving_script(self, script: str, numericals: Dict[str, float]) -> Dict[str, Any]:
        """Execute the generated solving script and return the result."""
        match = re.search(r'```python\s*([\s\S]*?)\s*```', script, re.DOTALL)  # Extract the code block
        if match:
            code_block = match.group(1)  # Get the code block
            # print('code block', code_block)  # Debug print
            function_name_match = re.search(r'def\s+(\w+)\(', code_block)  # Find function definition
            if not function_name_match:
                print("Error: Could not find function definition in the generated script.")
                return {}

            function_name = function_name_match.group(1)  # Get function name

            try:
                exec(code_block, globals())  # Execute the code block

                if function_name not in globals():
                    print(f"Error: Function '{function_name}' not found after executing the code block.")
                    return {}

                func = globals()[function_name]  # Get the function reference
                sig = inspect.signature(func)  # Get function signature

                args = []
                for param in sig.parameters.values():
                    if param.name in numericals:
                        args.append(numericals[param.name])  # Get numerical values for function arguments
                    else:
                        print(f"Warning: Parameter '{param.name}' not found in numericals. Using default value.")
                        args.append(param.default)  # Use default value if not found

                result = func(*args)  # Call the function with arguments
                if not isinstance(result, dict) or 'value' not in result or 'units' not in result:
                    print("Warning: Function result does not match expected format. Wrapping it in a standard format.")
                    return {"value": result, "units": "unknown"}  # Wrap result if format is incorrect
                return result
            except Exception as e:
                print(f"Error executing the solving script: {str(e)}")  # Handle execution errors
                return {}
        else:
            print("Error: Could not find code block in the generated script.")
            return {}

    def generate_answer_variations(self, question: str, correct_answer: Dict[str, Any], num_variations: int = 3) -> List[Dict[str, Any]]:
        """Generate variations of the correct answer."""
        json_output = self.answer_variation_chain.invoke({
            "question": question,
            "correct_answer": json.dumps(correct_answer),
            "num_variations": num_variations
        }).strip('```json\n')  # Invoke the answer variation chain
        try:
            return json.loads(json_output)  # Parse the JSON output
        except json.JSONDecodeError:
            print("Error: Invalid JSON output for answer variations")  # Handle JSON parsing errors
            return []

    def generate_question_set(self, subject: str, grade_level: str, topic: str, toughness_level: str, num_variations: int = 3) -> Dict[str, Any]:
        """Generate a complete set of questions, answers, and variations."""
        question = self.generate_question(subject, grade_level, topic, toughness_level)  # Generate a question
        numericals = self.extract_numericals(question)  # Extract numerical values
        solving_script = self.generate_solving_script(question, numericals)  # Generate solving script
        correct_answer = self.execute_solving_script(solving_script, numericals)  # Execute the script to get the answer
        answer_variations = self.generate_answer_variations(question, correct_answer, num_variations)  # Generate answer variations

        return {
            "question": question,
            "numericals": numericals,
            "solving_script": solving_script,
            "correct_answer": correct_answer,
            "answer_variations": answer_variations
        }

def setup_environment_variables():
    """Set up necessary environment variables for the application."""
    os.environ['OPENAI_API_KEY'] = openai_api_key = os.getenv('OPENAI_API_KEY')
    os.environ['LANGCHAIN_TRACING_V2'] = 'true'  # Enable tracing
    os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'  # Set Langchain endpoint
    os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')  # Set Langchain API key

# Remove the Streamlit main function and keep only the class and setup function


